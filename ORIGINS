/**
@Author:Sandeep Vuppula
*/

Hierarchical Dirichlet process (HDP):

HDP is an algorithm developed by Yee Whye Teh, Michael I. Jordan, Matthew J. Beal and David Blei:
The authors propose a clustering algorithm based on Hierarchical dirichlet processes (http://www.gatsby.ucl.ac.uk/~ywteh/research/npbayes/jasa2006.pdf)

@article{teh2012hierarchical,
  title={Hierarchical dirichlet processes},
  author={Teh, Yee Whye and Jordan, Michael I and Beal, Matthew J and Blei, David M},
  journal={Journal of the american statistical association},
  year={2012},
  publisher={Taylor \& Francis}
}

Our implementaion uses a python package developed by Jey Han Lau, Paul Cook, Diana McCarthy, David Newman and Timothy Baldwin that utilizes the above HDP implementation 
Word sense induction for novel sense detection
(http://www.ics.uci.edu/~newman/pubs/eacl2012.pdf)

@inproceedings{lau2012word,
  title={Word sense induction for novel sense detection},
  author={Lau, Jey Han and Cook, Paul and McCarthy, Diana and Newman, David and Baldwin, Timothy},
  booktitle={Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics},
  pages={591--601},
  year={2012},
  organization={Association for Computational Linguistics}
}

The code for the above paper has been taken from the Git Repository: https://github.com/jhlau/hdp-wsi
It includes the HDP implementation created by the authors of the first paper

NLTK: (URL: http://www.nltk.org/ )
Natural Lanaguage toolkit is a open-source python library which provides APIs that supports many natural language processing applications such as stemming, POS tagging, tokenizing etc. It is one of the most commonly used library for NLP applications. 

Functions we used from the NLTK:
*pos_tag, map_tag: (part of nltk.tag) Off-the-shelf taggers available in nltk.tag package. These use the Penn Treebank tagset.
*word_tokenize: A tokenizer that divides a given string into sub strings.
*ngrams: (part of nltk.util) A library that contains functions to work on various types of ngrams.
*nltk.collocations: A library that contains functions to work on collocations - Words that appear frequently in a corpora.
*RegexpTokenizer: (part of nltk.tokenize) A python class that contains functions to tokenize a given string using a regular expressions or a set of seperators between tokens.

Gensim: (URL: https://radimrehurek.com/gensim/)
Gensim is a python framework for vector space modelling. It contains many functions that support unsupervised semantic modelling from plain text.
*MmCorpus: gensim library containing tools for working with corpus in the Matrix Market format.
