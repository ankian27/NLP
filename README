____________________________________________________________________

		    Team - Red Project Stage I  
	Word sense disambiguation based on co-occurence matrices
____________________________________________________________________

Authors :  	Ankit Anand Gupta -
		Brandon Paulsen -
		Sai Ram Kowshik Vattipally -
		Sandeep Vuppula -
		


*************
CONTRIBUTIONS
*************
Ankit Anand Gupta : 

Brandon Paulsen :

Sai Ram Kowshik Vattipally :

Sandeep Vuppula :

********
CONTENTS
********

Contents in the Directory:
* install.sh
* runit.sh
* runall.sh
* README
* postProcessing.py
* writeToHDP.py
* stopwords.txt (The list of stop words we are excluding)
* hdp-wsi ( Directory that contains HDP word sense induction python implementation)
* senseclusters_scorer
* src
	DefinitionGeneration.py
	context.py
	corp.py
* output
* input
	abandon-verb-pauls658.xml
	racket-noun-pauls658.xml
	sidewalk-furnace-pauls658.xml
	
	wear-verb-vuppu008.xml
	plot-noun-vuppu008.xml
	television-food-vuppu008.xml

	strike-verb-gupta299.xml
	bat-noun-gupta299.xml
	banana-wall-gupta299.xml

	shoot-verb-vatti001.xml
	date-noun-vatti001.xml
	pigeon-car-vatti001-1.xml

********************
PROBLEM AND SOLUTION
********************
The problem we are trying to solve is creating a dictionary from raw data. The system takes a XML file containing a list of contexts each of which contain a target word within a <head></head> tag. Each instance is a sentence or a group of sentences that surround the target word which we intend to find the meaning of in the given context. The system we design is intended to group these contexts based on the sense of the target word in that particular context. Each of the resultant cluster will contain contexts where the target word is used in same sense. This step is called clustering.

The input file may be of 2 kinds. The first one has only one target word which is either a noun or verb which has multiple senses. The second kind is where there are contexts that uses two different words that are conflated into a single word. In the first kind, we try to cluster the contexts based on various senses the target word we have. In the second one, we try to assign a sense to the conflated word and try to group the contexts into clusters such that each cluster might have same sense as each word that the conflated word is formed from. Note that we might generate more or less clusters than the number of words used for conflating the word.

We then try to generate definitions of the target word in each cluster. The target word has different meanings(senses) in different contexts.

__________
Clustering
__________

We first parse the XML input file and extract each of the contexts seperately. We then tokenize each of the context and convert all the tokens to lower case alphabet. The tokenizer breaks certain words into contractions(For example "isn't" becomes "is + n't"). We then remove a selected list of stop words and words that have punctuations and numbers in them ( eg: n't, T2000) from the contexts. Then the resultant contexts as given as an input to the Hdp-wsi(Hierarchical Dirichlet process-Word sense Induction) tool in a suitable format. ***. The hdp-wsi tool extracts topics(senses) from the contexts and assigns descriptor words to each topic. Then we assign each context to a topic based on how well the context matches the descriptor words that belong to a particular topic. Then each of these topics become our senses that we extract from the given contexts.

Working of HDP:

Hierarchical Dirichlet process (HDP) is a algorithm used for clustering already grouped data. It takes N number of groups and clusters them into K groups. It is based on Dirichlet process. The number of groups is unknown prior to running the algorithm and is extracted from the data. We assume that each of our context is a group of its own and give them as an input to the HDP algorithm. The HDP algorithm clusters by finding similarity in latent structure between each of these groups. 

The Dirichlet process can be represented as 

DP(a_0, G_0)

*Alpha(a_0) is the scaling parameter and alpha >= 0. In simple terms, probability of a new cluster being generated is proportional to the a_0.

*Gamma(G_0) is the base probability measure. In other words, G_0 is the probability that a context goes into a newly generated cluster.

_____________________
Definition generation
_____________________

The topic words extracted in clustering will be used as the base words for definition generation. The 


**********
HOW TO RUN
**********

1) In terminal, navigate to the directory of project.
2) Run install.sh as "./install.sh"
3) Run runit.sh with the input file as the first argument.
	usage: "./runit.sh <senseval2-xml-file>"

Eg: To run our project on the file "date-noun-vatti001.xml", run as 
	./runit.sh test_data/date-noun-vatti001.xml

4) The reults will be displayed on the terminal.


********
EXAMPLES
********
-----------------
INPUT FILE FORMAT
-----------------
The input can be a file either of the following two kinds:

1)An XML with a single Noun or Verb tagged: (single word used in multiple senses)

Example file format:
--------------------

<corpus lang="english">
<lexelt item="line">
<instance id="1">
<answer instance="1" senseid="photograph or videograph a scene or a movie"/>
<context>
, " he says of his subjects. " When they look back, it's more than a portrait of them, it's a moment in place and time. " # As for Leon Borenzstein, he tells people who simply want to look good to go someplace else. But that doesn't stop him from getting clients. # " People are tired of sterile portraits, " he says. " They want something more creative. " # Whether they know it or not, apparently. When San Francisco fashion executive Naomi Mann hired Margretta Mitchell to <head>shoot</head> a family portrait, she asked for a couple of relatively straightforward photographs posed in the living room and garden. But Mitchell happened to snap the five Mann children grouped around a staircase while wearing big grins and goofy hats, and Mann liked it so much she bought that one instead. # " Even if you don't know our family, it speaks to you about who we are, " she says. " It's playful. It's funny. When I saw it, I said,
</context>
</instance>
<instance id="2">
<answer instance="2" senseid="photograph or videograph a scene or a movie"/>
<context>
o, Lesley Gore, fabulous woman, passed away over the weekend. And we also lost Louis Jourdan. Now do you remember a film called " Gigi? " Yes, and also was it " Octopussy, " was he also in that? Yes, he's, he was an amazing Frenchman. We also lost him this weekend. But the good news here is that Naya and Ryan, you both have a lot going on right now. Naya first, what's going on? Well, I am after this going to go and <head>shoot</head> a couple episodes of Lifetime's " Devious Maids. " So I'm excited about that, and it'll be cool to do something different, and all the ladies seem awesome. So I'm really looking forward to it. Yeah, they're all good girls. And what about you, Ryan? You can catch me on " General Hospital " as detective Nathan West. It's February, it's GH Fan February, so if you're a fan of the show, anything you
</context>
</instance>


2) An XML with a Name-conflate pair: (two words conflated into one used in two different senses)


Example file format:
--------------------

<?xml version="1.0" encoding="iso-8859-1" ?>
<corpus lang='english'>

<lexelt item="p_c">

<instance id="1">
<answer instance="1" senseid="pigeon"/>
<context>
 the genome and tissues, as well as the potential parenting, of the band-tailed <head>p_c</head> Patagioenas fasciata. # I've joined forces with a sweep of other interested scientists    fixed. But it is getting prettier. Now traveling under the name of 
</context>
</instance>

<instance id="2">
<answer instance="2" senseid="pigeon"/>
<context>
to beat either in the field or for dollar value -- and splice them into the genome of a stem cell from a common rock <head>p_c</head> # Rock pigeon stem cells containing this doctored genome could be transformed into germ    , and I know they are coming in on my frequency 
</context>
</instance>


******************
OUTPUT FILE FORMAT
******************



*********
CITATIONS
*********

1)Our main idea for clustering uses HDP (Hierarchical Dirichlet process), an algorithm developed by Yee Whye Teh, Michael I. Jordan, Matthew J. Beal and David Blei:
 Hierarchical dirichlet processes
(http://www.gatsby.ucl.ac.uk/~ywteh/research/npbayes/jasa2006.pdf)

@article{teh2012hierarchical,
  title={Hierarchical dirichlet processes},
  author={Teh, Yee Whye and Jordan, Michael I and Beal, Matthew J and Blei, David M},
  journal={Journal of the american statistical association},
  year={2012},
  publisher={Taylor \& Francis}
}


2) Our implementaion uses a python package developed by Jey Han Lau, Paul Cook, Diana McCarthy, David Newman and Timothy Baldwin that implemented HDP algorithm as outlined in the following paper: 
Word sense induction for novel sense detection
(http://www.ics.uci.edu/~newman/pubs/eacl2012.pdf)

@inproceedings{lau2012word,
  title={Word sense induction for novel sense detection},
  author={Lau, Jey Han and Cook, Paul and McCarthy, Diana and Newman, David and Baldwin, Timothy},
  booktitle={Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics},
  pages={591--601},
  year={2012},
  organization={Association for Computational Linguistics}
}




